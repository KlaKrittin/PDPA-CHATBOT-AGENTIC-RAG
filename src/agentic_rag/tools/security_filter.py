import os
import re
from typing import Dict, List, Tuple, Optional
import logging


try:
    from guardrails.validators import ProfanityFree  
except Exception:  
    ProfanityFree = None  


try:
    from openai import OpenAI  
except Exception:  
    OpenAI = None  

class SecurityFilter:
    """
    Security filter for PDPA Assistant to prevent inappropriate content and restrict topics to PDPA only.
    """
    
    def __init__(self):
   
        self.llama_base_url = os.getenv("LLAMA_CPP_BASE_URL", "http://localhost:8080/v1")
        self.llama_model = os.getenv("LLAMA_CPP_MODEL", os.getenv("OLLAMA_MODEL", "hf.co/scb10x/typhoon2.1-gemma3-4b-gguf:Q4_K_M"))
        self._openai_client = None
        if OpenAI is not None:
            try:
   
                self._openai_client = OpenAI(base_url=self.llama_base_url, api_key=os.getenv("OPENAI_API_KEY", "not-needed"))
            except Exception:
                self._openai_client = None

        self._profanity_validator = None
        if ProfanityFree is not None:
            try:
                self._profanity_validator = ProfanityFree()
            except Exception:
                self._profanity_validator = None

        self.thai_inappropriate_terms = [
            "‡∏´‡∏µ", "‡∏à‡∏¥‡πã‡∏°", "‡∏à‡∏π‡πã", "‡πÑ‡∏Ç‡πà", "‡∏´‡∏≥", "‡πÅ‡∏ï‡∏î", "‡∏´‡∏±‡∏ß‡∏ô‡∏°", "‡πÄ‡∏¢‡πá‡∏î",
            "‡∏õ‡∏µ‡πâ", "‡πÄ‡∏™‡∏µ‡∏¢‡∏ö", "‡πÄ‡∏™‡∏µ‡∏¢‡∏ß", "‡πÄ‡∏á‡∏µ‡πà‡∏¢‡∏ô", "‡∏Ç‡πà‡∏°‡∏Ç‡∏∑‡∏ô", "‡∏£‡∏∏‡∏°‡πÇ‡∏ó‡∏£‡∏°",
            "‡∏ô‡πâ‡∏≥‡πÅ‡∏ï‡∏Å", "‡πÅ‡∏ï‡∏Å‡πÉ‡∏ô", "‡∏™‡∏ß‡∏¥‡∏á‡∏Å‡∏¥‡πâ‡∏á", "‡∏™‡∏ß‡∏¥‡πâ‡∏á‡∏Å‡∏¥‡πâ‡∏á", "‡∏î‡∏π‡∏î‡∏õ‡∏≤‡∏Å", "‡∏≠‡∏°‡∏Ñ‡∏ß‡∏¢", "‡πÄ‡∏•‡∏µ‡∏¢‡∏´‡∏µ",
            "‡∏ï‡∏π‡∏î", "‡∏™‡πâ‡∏ô‡∏ï‡∏µ‡∏ô", "‡∏ï‡∏µ‡∏ô", "‡∏ï‡∏≠‡πÅ‡∏´‡∏•", "‡∏û‡πà‡∏≠‡∏á", "‡∏û‡πà‡∏≠‡∏°‡∏∂‡∏á", "‡πÅ‡∏°‡πà‡∏°‡∏∂‡∏á", "‡∏û‡πà‡∏≠‡∏°‡∏∂‡∏á‡∏ï‡∏≤‡∏¢",
            "‡πÅ‡∏°‡πà‡∏°‡∏∂‡∏á‡∏ï‡∏≤‡∏¢", "‡πÄ‡∏´‡∏µ‡πâ‡∏¢", "‡πÄ‡∏Æ‡∏µ‡πâ‡∏¢", "‡πÄ‡∏´‡πâ", "‡∏´‡πà‡∏≤", "‡∏™‡∏±‡∏î", "‡∏™‡∏±‡∏™", "‡πÄ‡∏ä‡∏µ‡πà‡∏¢",
            "‡πÄ‡∏ä‡∏µ‡πâ‡∏¢", "‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡πÄ‡∏≠‡πâ‡∏¢", "‡πÄ‡∏ä‡∏µ‡πâ‡∏¢‡πÄ‡∏≠‡πâ‡∏¢", "‡πÅ‡∏°‡πà‡∏á", "‡∏°‡∏∂‡∏á", "‡∏Å‡∏π", "‡πÑ‡∏≠‡∏™‡∏±‡∏î", "‡πÑ‡∏≠‡πâ‡∏™‡∏±‡∏î",
            "‡πÑ‡∏≠‡∏™‡∏±‡∏™", "‡πÑ‡∏≠‡πâ‡∏™‡∏±‡∏™", "‡πÑ‡∏≠‡πâ‡πÄ‡∏´‡∏µ‡πâ‡∏¢", "‡∏≠‡∏µ‡πÄ‡∏´‡∏µ‡πâ‡∏¢", "‡πÄ‡∏´‡∏µ‡πâ‡∏¢‡∏°‡∏≤‡∏Å", "‡πÄ‡∏´‡∏µ‡πâ‡∏¢‡∏™‡∏∏‡∏î", "‡πÑ‡∏≠‡πâ‡∏´‡πà‡∏≤",
            "‡πÑ‡∏≠‡∏™‡∏≤‡∏î", "‡πÑ‡∏≠‡∏™‡∏≤‡∏î‡∏î", "‡∏™‡∏±‡∏ï‡∏ß‡πå", "‡∏ä‡∏≤‡∏ï‡∏¥‡∏´‡∏°‡∏≤", "‡πÑ‡∏≠‡πâ‡∏ä‡∏≤‡∏ï‡∏¥‡∏´‡∏°‡∏≤", "‡πÑ‡∏≠‡πâ‡πÄ‡∏ß‡∏£", "‡πÑ‡∏≠‡πâ‡πÄ‡∏ß‡∏£‡∏ï‡∏∞‡πÑ‡∏•",
            "‡πÑ‡∏≠‡πâ‡∏Ñ‡∏ß‡∏≤‡∏¢", "‡∏Ñ‡∏ß‡∏≤‡∏¢", "‡πÑ‡∏≠‡πâ‡πÇ‡∏á‡πà", "‡πÇ‡∏á‡πà‡πÄ‡∏á‡πà‡∏≤", "‡πÇ‡∏á‡πà‡∏Ñ‡∏ß‡∏≤‡∏¢", "‡∏õ‡∏±‡∏ç‡∏ç‡∏≤‡∏≠‡πà‡∏≠‡∏ô", "‡πÑ‡∏£‡πâ‡∏™‡∏°‡∏≠‡∏á",
            "‡∏™‡∏°‡∏≠‡∏á‡∏´‡∏°‡∏≤", "‡πÑ‡∏≠‡πâ‡∏ö‡πâ‡∏≤", "‡∏™‡∏ß‡∏∞", "‡πÄ‡∏Æ‡∏á‡∏ã‡∏ß‡∏¢", "‡∏£‡∏∞‡∏¢‡∏≥", "‡πÑ‡∏≠‡πâ‡∏£‡∏∞‡∏¢‡∏≥", "‡∏™‡∏ñ‡∏∏‡∏ô", "‡πÑ‡∏≠‡πâ‡∏™‡∏ñ‡∏∏‡∏ô",
            "‡∏ï‡πà‡∏≥‡∏ï‡∏°", "‡∏≠‡∏±‡∏õ‡∏£‡∏µ‡∏¢‡πå", "‡∏à‡∏±‡∏ç‡πÑ‡∏£", "‡∏Å‡∏£‡∏∞‡∏´‡∏£‡∏µ‡πà", "‡∏Å‡∏∞‡∏´‡∏£‡∏µ‡πà", "‡∏Å‡∏£‡∏∞‡∏£‡∏µ‡πà", "‡∏Å‡∏∞‡∏£‡∏µ‡πà", "‡∏≠‡∏µ‡∏ï‡∏±‡∏ß", "‡∏≠‡∏µ‡πÅ‡∏û‡∏®‡∏¢‡∏≤", "‡πÅ‡∏û‡∏®‡∏¢‡∏≤",
            "‡∏≠‡∏µ‡∏î‡∏≠‡∏Å", "‡∏î‡∏≠‡∏Å‡∏ó‡∏≠‡∏á", "‡∏´‡∏ô‡πâ‡∏≤‡∏Ñ‡∏ß‡∏¢", "‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏µ", "‡πÑ‡∏≠‡πâ‡∏´‡∏ô‡πâ‡∏≤‡∏Ñ‡∏ß‡∏¢", "‡πÑ‡∏≠‡πâ‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏µ",
            "‡∏ä‡∏¥‡∏ö‡∏´‡∏≤‡∏¢", "‡∏ä‡∏¥‡∏ö‡∏´‡∏≤‡∏¢‡∏ß‡∏≤‡∏¢‡∏ß‡∏≠‡∏î", "‡πÑ‡∏≠‡πâ‡∏™‡∏≤‡∏£‡πÄ‡∏•‡∏ß", "‡∏™‡∏≤‡∏£‡πÄ‡∏•‡∏ß", "‡πÄ‡∏•‡∏ß", "‡∏™‡∏ñ‡∏∏‡∏ô‡∏°‡∏≤‡∏Å",
            "‡∏´‡∏ô‡πâ‡∏≤‡∏î‡πâ‡∏≤‡∏ô", "‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏ô‡∏≤", "‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏±‡∏ß‡πÄ‡∏°‡∏µ‡∏¢", "‡∏Å‡∏≤‡∏Å", "‡∏Ç‡∏¢‡∏∞‡∏™‡∏±‡∏á‡∏Ñ‡∏°", "‡∏°‡∏∞‡πÄ‡∏£‡πá‡∏á‡∏™‡∏±‡∏á‡∏Ñ‡∏°",
            "‡∏Ñ‡∏ß‡∏¢‡πÉ‡∏´‡∏ç‡πà", "‡∏Ñ‡∏ß‡∏¢‡∏¢‡∏≤‡∏ß", "‡∏Ñ‡∏ß‡∏¢‡πÄ‡∏î‡πá‡∏Å", "‡∏´‡∏µ‡∏ö‡∏≤‡∏ô", "‡∏´‡∏µ‡πÄ‡∏î‡πá‡∏Å", "‡∏´‡∏µ‡πÄ‡∏ô‡πà‡∏≤", "‡∏à‡∏¥‡πã‡∏°‡πÄ‡∏î‡πá‡∏Å",
            "‡πÅ‡∏ï‡∏Å‡∏Ñ‡∏≤‡∏õ‡∏≤‡∏Å", "‡πÅ‡∏ï‡∏Å‡∏Ñ‡∏≤", "‡πÅ‡∏ï‡∏Å‡πÉ‡∏™‡πà‡∏´‡∏ô‡πâ‡∏≤", "‡πÅ‡∏ï‡∏Å‡πÉ‡∏™‡πà‡∏õ‡∏≤‡∏Å", "‡πÄ‡∏™‡∏£‡πá‡∏à‡πÉ‡∏ô", "‡∏Ç‡∏¢‡πà‡∏°", "‡∏Ç‡∏¢‡∏µ‡πâ",
            "‡∏Ç‡∏∂‡πâ‡∏ô‡∏Ñ‡∏£‡πà‡∏≠‡∏°", "‡∏Å‡∏£‡∏∞‡πÅ‡∏ó‡∏Å", "‡πÄ‡∏≠‡∏≤‡∏Å‡∏±‡∏ô", "‡πÄ‡∏≠‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ß‡πà‡∏≤", "‡πÄ‡∏≠‡∏≤‡πÅ‡∏£‡∏á‡πÜ", "‡πÄ‡∏≠‡∏≤‡πÅ‡∏£‡∏á‡πÅ‡∏£‡∏á",
            "‡πÄ‡∏•‡∏µ‡∏¢", "‡∏î‡∏π‡∏î",  "‡πÅ‡∏´‡∏¢‡πà", "‡πÄ‡∏™‡∏µ‡∏¢‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤", "‡∏™‡∏≠‡∏î‡πÄ‡∏Ç‡πâ‡∏≤",
            "‡∏ï‡πà‡∏≥‡∏ï‡∏°", "‡∏≠‡∏±‡∏õ‡∏£‡∏µ‡∏¢‡πå", "‡∏à‡∏±‡∏ç‡πÑ‡∏£", "‡∏Å‡∏£‡∏∞‡∏´‡∏£‡∏µ‡πà", "‡∏Å‡∏∞‡∏´‡∏£‡∏µ‡πà", "‡∏≠‡∏µ‡∏ï‡∏±‡∏ß", "‡∏≠‡∏µ‡πÅ‡∏û‡∏®‡∏¢‡∏≤", "‡πÅ‡∏û‡∏®‡∏¢‡∏≤",
            "‡∏≠‡∏µ‡∏î‡∏≠‡∏Å", "‡∏î‡∏≠‡∏Å‡∏ó‡∏≠‡∏á", "‡∏´‡∏ô‡πâ‡∏≤‡∏Ñ‡∏ß‡∏¢", "‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏µ", "‡πÑ‡∏≠‡πâ‡∏´‡∏ô‡πâ‡∏≤‡∏Ñ‡∏ß‡∏¢", "‡πÑ‡∏≠‡πâ‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏µ"
        ]


        thai_variant_patterns = [
            r"‡∏Ñ\s*‡∏ß‡∏¢(?:‡∏¢+)?",                    
            r"(?:‡πÑ‡∏≠‡πâ|‡∏≠‡∏µ)?\s*‡πÄ‡∏´‡∏µ‡πâ‡∏¢(?:‡∏¢+)?",   
            r"(?:‡πÑ‡∏≠‡πâ|‡∏≠‡∏µ)?\s*‡∏™‡∏±‡∏î",          
            r"(?:‡πÑ‡∏≠‡πâ|‡∏≠‡∏µ)?\s*‡∏™‡∏±‡∏™",          
            r"(?:‡πÑ‡∏≠‡πâ|‡∏≠‡∏µ)?\s*‡πÄ‡∏ß‡∏£(?:‡∏ï‡∏∞‡πÑ‡∏•)?", 
            r"(?:‡πÑ‡∏≠‡πâ|‡∏≠‡∏µ)?\s*‡∏Ñ‡∏ß‡∏≤‡∏¢",        
            r"(?:‡πÑ‡∏≠‡πâ|‡∏≠‡∏µ)?\s*‡∏£‡∏∞‡∏¢‡∏≥",        
            r"(?:‡πÑ‡∏≠‡πâ|‡∏≠‡∏µ)?\s*‡∏™‡∏ñ‡∏∏‡∏ô",        
            r"‡∏ä‡∏≤‡∏ï‡∏¥\s*‡∏´‡∏°‡∏≤",                 
            r"‡∏´‡∏ô‡πâ‡∏≤\s*‡∏Ñ‡∏ß‡∏¢",                 
            r"‡∏´‡∏ô‡πâ‡∏≤\s*‡∏´‡∏µ"                   
        ]


        thai_literals_pattern = "|".join(map(re.escape, self.thai_inappropriate_terms))
        thai_pattern = rf"({thai_literals_pattern}|{'|'.join(thai_variant_patterns)})"

 
        self.english_inappropriate_terms = [
            "fuck", "motherfucker", "mf", "shit", "bullshit", "bs", "bitch",
            "slut", "whore", "cunt", "pussy", "dick", "cock", "asshole",
            "ass", "bastard", "son of a bitch", "sob", "bloody hell",
            "goddamn", "god damn", "damn", "prick", "wanker", "twat"
        ]
        english_variant_patterns = [
            r"f\*+k", r"fxxk", r"sh\*t", r"b!tch"
        ]
        english_literals_pattern = "|".join(map(re.escape, self.english_inappropriate_terms))
        english_pattern = rf"\\b({english_literals_pattern}|{'|'.join(english_variant_patterns)})\\b"


        self.security_avoid_terms = [
            "crack", "cracker", "cracking", "exploit", "vulnerability", "intrusion",
            "malware", "virus", "trojan", "ransomware", "phishing", "spam", "ddos",
            "sql injection", "xss", "csrf", "buffer overflow", "privilege escalation",
            "rootkit", "backdoor", "keylogger", "spyware", "adware", "botnet", "worm",
            "logic bomb", "time bomb", "easter egg", "trapdoor", "trap door", "trap-door",
            "trap_door"
        ]
        security_pattern = rf"\\b({'|'.join(map(re.escape, self.security_avoid_terms))})\\b"

        self.violence_terms_th = ["‡∏Ü‡πà‡∏≤", "‡∏Ü‡∏≤‡∏ï‡∏Å‡∏£‡∏£‡∏°", "‡∏Ü‡∏≤‡∏ï‡∏Å‡∏£"]

        violence_th_pattern = rf"(?<![‡∏Å-‡πô])({'|'.join(map(re.escape, self.violence_terms_th))})(?![‡∏Å-‡πô])"
        self.violence_terms_en = [
            "kill", "murder", "murderer", "assassinate", "assassin", "execute",
            "execution", "suicide", "suicidal", "terrorism", "terrorist", "bomb",
            "explosion", "gun", "weapon", "violence", "violent", "attack", "assault",
            "threat", "threatening"
        ]
        violence_en_pattern = rf"\\b({'|'.join(map(re.escape, self.violence_terms_en))})\\b"


        self.drug_terms_th = ["‡∏¢‡∏≤‡πÄ‡∏™‡∏û‡∏ï‡∏¥‡∏î", "‡∏¢‡∏≤‡πÄ‡∏™‡∏û"]

        drug_th_pattern = rf"(?<![‡∏Å-‡πô])({'|'.join(map(re.escape, self.drug_terms_th))})(?![‡∏Å-‡πô])"
        self.drug_terms_en = [
            "drug", "drugs", "heroin", "cocaine", "marijuana", "weed", "meth",
            "amphetamine", "ecstasy", "lsd", "pills", "overdose", "addiction",
            "addict", "dealer", "trafficking", "smuggling"
        ]
        drug_en_pattern = rf"\\b({'|'.join(map(re.escape, self.drug_terms_en))})\\b"

        self.inappropriate_patterns = [
            thai_pattern,
            english_pattern,
            security_pattern,
            violence_th_pattern,
            violence_en_pattern,
            drug_th_pattern,
            drug_en_pattern,
        ]
        

        self.pdpa_keywords = []
        

        self.inappropriate_regex = re.compile('|'.join(self.inappropriate_patterns), re.IGNORECASE)

        self.injection_phrases = [
            r"ignore (all|any) (previous|prior) (instructions|messages)",
            r"disregard (the )?(rules|system|guardrails)",
            r"act as (?:an?|the) (?:admin|developer|system)",
            r"reveal (?:your )?(?:system|hidden) prompt",
            r"jailbreak|do-anything-now|DAN",
            r"override safety|bypass safety|disable safety",
            r"‡πÄ‡∏û‡∏¥‡∏Å‡πÄ‡∏â‡∏¢‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤|‡∏•‡∏∞‡πÄ‡∏•‡∏¢‡∏Å‡∏é|‡πÅ‡∏™‡∏î‡∏á system prompt|‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢|‡∏Ç‡πâ‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î",
        ]
        self.injection_regex = re.compile('|'.join(self.injection_phrases), re.IGNORECASE)


        self.email_regex = re.compile(r"[a-zA-Z0-9_.+\-]+@[a-zA-Z0-9\-]+\.[a-zA-Z0-9\-.]+")
        self.phone_regex = re.compile(r"(?:\+?66|0)[\s\-]?(?:\d[\s\-]?){8,10}")

        self.thai_id_regex = re.compile(r"\b\d{1}-?\d{4}-?\d{5}-?\d{2}-?\d{1}\b")
        

        self.logger = logging.getLogger(__name__)
    
    def check_content_safety(self, text: str) -> Tuple[bool, List[str]]:
        """
        Content safety check using Guardrails profanity validator if available,
        with fallback to regex-based detection of severe profanity/violence, etc.
        
        Args:
            text: The text to check
            
        Returns:
            Tuple of (is_safe, list_of_violations)
        """
        if not text:
            return True, []
        
        violations = []
        text_lower = text.lower()


        if self._profanity_validator is not None:
            try:

                is_clean = True
                message = None
                if hasattr(self._profanity_validator, "validate"):
                    result = self._profanity_validator.validate(text_lower)  # type: ignore

                    if isinstance(result, tuple) and len(result) >= 2:

                        _, err = result[0], result[1]
                        is_clean = err is None
                        message = None if err is None else str(err)
                    elif isinstance(result, dict):

                        is_clean = bool(result.get("is_valid", True))
                        message = result.get("error")
                    else:

                        is_clean = True
                else:

                    _ = self._profanity_validator(text_lower) 

                if not is_clean:
                    violations.append("‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏Ñ‡∏≥‡∏´‡∏¢‡∏≤‡∏ö‡∏à‡∏≤‡∏Å Guardrails Profanity validator" if not message else message)
            except Exception:
                pass
        
        matches = self.inappropriate_regex.findall(text_lower)
        if matches:
            flat_matches = []
            for match in matches:
                if isinstance(match, tuple):
                    flat_matches.extend([m for m in match if m])
                else:
                    flat_matches.append(match)
            if flat_matches:
                violations.append(f"‡∏û‡∏ö‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°: {', '.join(set(flat_matches))}")
        
        extreme_security_terms = [
            "create malware", "create virus", "create trojan", "create ransomware",
            "make malware", "make virus", "make trojan", "make ransomware",
            "build malware", "build virus", "build trojan", "build ransomware",
            "develop malware", "develop virus", "develop trojan", "develop ransomware"
        ]
        
        found_extreme_terms = []
        for term in extreme_security_terms:
            if term.lower() in text_lower:
                found_extreme_terms.append(term)
        
        if found_extreme_terms:
            violations.append(f"‡∏û‡∏ö‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏°‡∏±‡∏•‡πÅ‡∏ß‡∏£‡πå: {', '.join(found_extreme_terms)}")
        
        is_safe = len(violations) == 0
        
        if not is_safe:
            self.logger.warning(f"Content safety violation detected: {violations}")
        
        return is_safe, violations

    def _ai_check_pdpa_related(self, text: str) -> Tuple[bool, str]:
        """
        Determine PDPA-relatedness using ONLY the AI judgment (per request).
        If the AI is not available, treat as not related and ask user to ask about PDPA.
        Returns (is_related, reason_text).
        """
        if not text or self._openai_client is None:
            return False, "AI unavailable for PDPA check"

        try:
            system = (
                "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢ PDPA ‡πÑ‡∏ó‡∏¢ ‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡∏ß‡πà‡∏≤ '‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö PDPA ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà' ‡∏à‡∏≤‡∏Å‡∏™‡∏≤‡∏£‡∏∞‡∏ó‡∏≤‡∏á‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢ ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÅ‡∏Ñ‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ PDPA\n"
                "- ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á: ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏Ç‡∏≠‡∏á‡πÄ‡∏à‡πâ‡∏≤‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡∏Ç‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á/‡∏•‡∏ö/‡∏ñ‡∏≠‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏¥‡∏ô‡∏¢‡∏≠‡∏°/‡∏Ñ‡∏±‡∏î‡∏Ñ‡πâ‡∏≤‡∏ô), ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°/‡∏ú‡∏π‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•, ‡∏ê‡∏≤‡∏ô‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢ (‡∏¢‡∏¥‡∏ô‡∏¢‡∏≠‡∏°/‡∏™‡∏±‡∏ç‡∏ç‡∏≤/‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Å‡∏°./‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏ä‡∏≠‡∏ö‡∏ò‡∏£‡∏£‡∏°/‡∏†‡∏≤‡∏£‡∏Å‡∏¥‡∏à‡∏£‡∏±‡∏ê/‡∏™‡∏≤‡∏ò‡∏≤‡∏£‡∏ì‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå), ‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡πá‡∏ö-‡πÉ‡∏ä‡πâ-‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏ú‡∏¢-‡πÇ‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏°‡πÅ‡∏î‡∏ô, ‡∏Å‡∏≤‡∏£‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏´‡∏ï‡∏∏‡∏•‡∏∞‡πÄ‡∏°‡∏¥‡∏î, ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•, DPO, DPIA, ‡∏™‡∏±‡∏ç‡∏ç‡∏≤ data processing, ‡∏Å‡∏≤‡∏£‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û/‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ó‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏ú‡∏¢‡πÅ‡∏û‡∏£‡πà‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå, CCTV/‡πÑ‡∏ö‡πÇ‡∏≠‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å‡∏ã‡πå/‡∏Ñ‡∏∏‡∏Å‡∏Å‡∏µ‡πâ/‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î‡∏ï‡∏£‡∏á‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•\n"
                "- ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á: ‡πÅ‡∏Ñ‡πà‡πÄ‡∏≠‡πà‡∏¢‡∏ä‡∏∑‡πà‡∏≠ PDPA ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ PDPA ‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤/‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£/‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤/‡∏Å‡∏£‡∏∞‡πÄ‡∏õ‡πã‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏∏‡πâ‡∏°‡∏Ñ‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•\n"
                "- ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á: '‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡∏ï‡∏¥‡∏î‡∏Ñ‡∏ô‡∏≠‡∏∑‡πà‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡πÇ‡∏û‡∏™‡∏ï‡πå‡πÑ‡∏î‡πâ‡πÑ‡∏´‡∏°', '‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏¥‡∏ô‡∏¢‡∏≠‡∏°‡πÑ‡∏´‡∏°', '‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏Ç‡∏≠‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•', '‡∏ê‡∏≤‡∏ô‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡πÉ‡∏î‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ', '‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏´‡∏ï‡∏∏‡∏•‡∏∞‡πÄ‡∏°‡∏¥‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÉ‡∏î', '‡πÇ‡∏≠‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≠‡∏Å‡∏ô‡∏≠‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£'\n"
                "- ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á: '‡∏Å‡∏£‡∏∞‡πÄ‡∏õ‡πã‡∏≤ PDPA ‡∏£‡∏≤‡∏Ñ‡∏≤‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà', 'PDPA ‡∏Ñ‡∏∑‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£', '‡∏û‡∏π‡∏î‡∏ñ‡∏∂‡∏á PDPA ‡πÅ‡∏ï‡πà‡∏ñ‡∏≤‡∏°‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏Å‡∏°‡∏´‡∏£‡∏∑‡∏≠‡∏´‡∏∏‡πâ‡∏ô'\n"
                "‡∏ï‡∏≠‡∏ö‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö: '‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á: ' ‡∏´‡∏£‡∏∑‡∏≠ '‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á: ' ‡πÉ‡∏´‡πâ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏ß‡πà‡∏≤‡∏ó‡∏≥‡πÑ‡∏°‡∏ñ‡∏∂‡∏á‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á ‡πÉ‡∏´‡πâ‡∏Ñ‡∏¥‡∏î‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á"
            )
            prompt = f"‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {text}\n‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏™‡∏±‡πâ‡∏ô ‡πÜ ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô"
            resp = self._openai_client.chat.completions.create(
                model=self.llama_model,
                messages=[{"role": "system", "content": system}, {"role": "user", "content": prompt}],
                max_tokens=120,
                temperature=0
            )
            content = (resp.choices[0].message.content or "").strip()
            norm = content.replace("\u200b", "").strip().lower()

            if norm.startswith("y:") or norm.startswith("‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á"):
                return True, content
            if norm.startswith("n:") or norm.startswith("‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á"):
                return False, content

            return False, content or "‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å AI"
        except Exception as e:
            return False, "AI error during PDPA check"

    def _is_severe_profanity(self, text: str, violations: List[str]) -> bool:
        """
        Check if the profanity is severe enough to block the question.
        
        Args:
            text: The text to check
            violations: List of safety violations found
            
        Returns:
            True if the profanity is severe, False otherwise
        """
        if not violations:
            return False

        severe_patterns = [

            "‡πÄ‡∏¢‡πá‡∏î", "‡∏õ‡∏µ‡πâ", "‡∏™‡∏≠‡∏î", "‡πÄ‡∏™‡∏µ‡∏¢‡∏ö", "‡πÄ‡∏™‡∏µ‡∏¢‡∏ß", "‡πÄ‡∏á‡∏µ‡πà‡∏¢‡∏ô", "‡∏Ç‡πà‡∏°‡∏Ç‡∏∑‡∏ô", "‡∏£‡∏∏‡∏°‡πÇ‡∏ó‡∏£‡∏°",
            "‡∏ô‡πâ‡∏≥‡πÅ‡∏ï‡∏Å", "‡πÅ‡∏ï‡∏Å‡πÉ‡∏ô", "‡∏™‡∏ß‡∏¥‡∏á‡∏Å‡∏¥‡πâ‡∏á", "‡∏™‡∏ß‡∏¥‡πâ‡∏á‡∏Å‡∏¥‡πâ‡∏á", "‡∏î‡∏π‡∏î‡∏õ‡∏≤‡∏Å", "‡∏≠‡∏°‡∏Ñ‡∏ß‡∏¢", "‡πÄ‡∏•‡∏µ‡∏¢‡∏´‡∏µ",
            "‡∏Ñ‡∏ß‡∏¢‡πÉ‡∏´‡∏ç‡πà", "‡∏Ñ‡∏ß‡∏¢‡∏¢‡∏≤‡∏ß", "‡∏Ñ‡∏ß‡∏¢‡πÄ‡∏î‡πá‡∏Å", "‡∏´‡∏µ‡∏ö‡∏≤‡∏ô", "‡∏´‡∏µ‡πÄ‡∏î‡πá‡∏Å", "‡∏´‡∏µ‡πÄ‡∏ô‡πà‡∏≤", "‡∏à‡∏¥‡πã‡∏°‡πÄ‡∏î‡πá‡∏Å",
            "‡πÅ‡∏ï‡∏Å‡∏Ñ‡∏≤‡∏õ‡∏≤‡∏Å", "‡πÅ‡∏ï‡∏Å‡∏Ñ‡∏≤", "‡πÅ‡∏ï‡∏Å‡πÉ‡∏™‡πà‡∏´‡∏ô‡πâ‡∏≤", "‡πÅ‡∏ï‡∏Å‡πÉ‡∏™‡πà‡∏õ‡∏≤‡∏Å", "‡πÄ‡∏™‡∏£‡πá‡∏à‡πÉ‡∏ô", "‡∏Ç‡∏¢‡πà‡∏°", "‡∏Ç‡∏¢‡∏µ‡πâ",
            "‡∏Ç‡∏∂‡πâ‡∏ô‡∏Ñ‡∏£‡πà‡∏≠‡∏°", "‡∏Å‡∏£‡∏∞‡πÅ‡∏ó‡∏Å", "‡πÄ‡∏≠‡∏≤‡∏Å‡∏±‡∏ô", "‡πÄ‡∏≠‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ß‡πà‡∏≤", "‡πÄ‡∏≠‡∏≤‡πÅ‡∏£‡∏á‡πÜ", "‡πÄ‡∏≠‡∏≤‡πÅ‡∏£‡∏á‡πÅ‡∏£‡∏á",
            "‡πÄ‡∏•‡∏µ‡∏¢", "‡∏î‡∏π‡∏î", "‡∏≠‡∏°", "‡∏¢‡∏±‡∏î", "‡πÅ‡∏´‡∏¢‡πà", "‡πÄ‡∏™‡∏µ‡∏¢‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤", "‡∏™‡∏≠‡∏î‡πÄ‡∏Ç‡πâ‡∏≤",
            

            "‡∏û‡πà‡∏≠‡∏°‡∏∂‡∏á‡∏ï‡∏≤‡∏¢", "‡πÅ‡∏°‡πà‡∏°‡∏∂‡∏á‡∏ï‡∏≤‡∏¢", "‡∏ä‡∏¥‡∏ö‡∏´‡∏≤‡∏¢", "‡∏ä‡∏¥‡∏ö‡∏´‡∏≤‡∏¢‡∏ß‡∏≤‡∏¢‡∏ß‡∏≠‡∏î", "‡πÑ‡∏≠‡πâ‡∏™‡∏≤‡∏£‡πÄ‡∏•‡∏ß", "‡∏™‡∏≤‡∏£‡πÄ‡∏•‡∏ß",
            "‡∏´‡∏ô‡πâ‡∏≤‡∏î‡πâ‡∏≤‡∏ô", "‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏ô‡∏≤", "‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏±‡∏ß‡πÄ‡∏°‡∏µ‡∏¢", "‡∏Å‡∏≤‡∏Å", "‡∏Ç‡∏¢‡∏∞‡∏™‡∏±‡∏á‡∏Ñ‡∏°", "‡∏°‡∏∞‡πÄ‡∏£‡πá‡∏á‡∏™‡∏±‡∏á‡∏Ñ‡∏°",
            "‡∏Å‡∏£‡∏∞‡∏´‡∏£‡∏µ‡πà", "‡∏Å‡∏∞‡∏´‡∏£‡∏µ‡πà", "‡∏Å‡∏£‡∏∞‡∏£‡∏µ‡πà", "‡∏Å‡∏∞‡∏£‡∏µ‡πà", "‡∏≠‡∏µ‡∏ï‡∏±‡∏ß", "‡∏≠‡∏µ‡πÅ‡∏û‡∏®‡∏¢‡∏≤", "‡πÅ‡∏û‡∏®‡∏¢‡∏≤",
            "‡∏≠‡∏µ‡∏î‡∏≠‡∏Å", "‡∏î‡∏≠‡∏Å‡∏ó‡∏≠‡∏á", "‡∏´‡∏ô‡πâ‡∏≤‡∏Ñ‡∏ß‡∏¢", "‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏µ", "‡πÑ‡∏≠‡πâ‡∏´‡∏ô‡πâ‡∏≤‡∏Ñ‡∏ß‡∏¢", "‡πÑ‡∏≠‡πâ‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏µ",
            
   
            "fuck", "motherfucker", "cunt", "pussy", "dick", "cock", "asshole",
            "bitch", "slut", "whore", "bastard", "son of a bitch"
        ]
        
        text_lower = text.lower()
        
        for pattern in severe_patterns:
            if pattern.lower() in text_lower:
                return True
        
        mild_profanities = ["‡∏°‡∏∂‡∏á", "‡∏Å‡∏π", "‡πÄ‡∏´‡∏µ‡πâ‡∏¢", "‡πÄ‡∏Æ‡∏µ‡πâ‡∏¢", "‡πÄ‡∏´‡πâ", "‡∏´‡πà‡∏≤", "‡∏™‡∏±‡∏î", "‡∏™‡∏±‡∏™", "‡πÄ‡∏ä‡∏µ‡πà‡∏¢", "‡πÄ‡∏ä‡∏µ‡πâ‡∏¢", "‡πÅ‡∏°‡πà‡∏á"]
        mild_count = sum(1 for word in mild_profanities if word in text_lower)
        
        if mild_count > 2:
            return True
        
        return False

    def detect_prompt_injection(self, text: str) -> List[str]:
        """
        Detect likely prompt-injection attempts using heuristic patterns.
        Returns list of matched phrases (empty if none).
        """
        if not text:
            return []
        matches = self.injection_regex.findall(text)

        flat = []
        for m in matches:
            if isinstance(m, tuple):
                flat.extend([x for x in m if x])
            else:
                flat.append(m)
        return list(set(flat))

    def sanitize_pii(self, text: str) -> str:
        """
        Redact common PII patterns from text.
        """
        if not text:
            return text
        redacted = self.email_regex.sub('[REDACTED_EMAIL]', text)
        redacted = self.phone_regex.sub('[REDACTED_PHONE]', redacted)
        redacted = self.thai_id_regex.sub('[REDACTED_THAI_ID]', redacted)
        return redacted
    
    def check_topic_restriction(self, text: str) -> Tuple[bool, List[str]]:
        """
        Check if the text is related to PDPA topics only.
        
        Args:
            text: The text to check
            
        Returns:
            Tuple of (is_pdpa_related, list_of_reasons)
        """
        if not text:
            return False, ["‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤"]
        
        text_lower = text.lower()
        

        pdpa_matches = []
        

        legal_privacy_terms = [
            "‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢", "‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏∏‡πâ‡∏°‡∏Ñ‡∏£‡∏≠‡∏á", "‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", "‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•",
            "privacy", "legal", "law", "regulation", "compliance", "governance",
            "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•", "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß", "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•",
            "data", "personal", "private", "confidential", "sensitive",

            "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢", "security", "protection", "‡∏Ñ‡∏∏‡πâ‡∏°‡∏Ñ‡∏£‡∏≠‡∏á", "protect",
            "‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß", "privacy", "‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß", "private",
            "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", "information", "data", "‡∏™‡∏≤‡∏£‡∏™‡∏ô‡πÄ‡∏ó‡∏®",
            "‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢", "law", "regulation", "‡∏Å‡∏é‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö",
            "‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£", "management", "‡∏Å‡∏≤‡∏£‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£", "administration"
        ]
        
        legal_matches = []
        for term in legal_privacy_terms:
            if term.lower() in text_lower:
                legal_matches.append(term)
        
        if legal_matches:
            return True, [f"‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢/‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß: {', '.join(legal_matches[:3])}"]
        
        return False, ["‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö PDPA ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏∏‡πâ‡∏°‡∏Ñ‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•"]
    
    def filter_user_input(self, user_input: str) -> Dict[str, any]:
        """
        [CORRECTED LOGIC]
        ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Input ‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:
        1. ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÇ‡∏à‡∏°‡∏ï‡∏µ (Injection) -> ‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
        2. ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° (Profanity) -> ‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
        3. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö PDPA ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà -> ‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß
        """

        result = {
            "is_safe": True,
            "is_pdpa_related": True,
            "violations": [],
            "reasons": [],
            "filtered_text": user_input,
            "should_respond": True,
            "response_message": ""
        }

      
        injection_hits = self.detect_prompt_injection(user_input)
        if injection_hits:
            result["should_respond"] = False
            result["response_message"] = "‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏à‡∏°‡∏ï‡∏µ‡∏£‡∏∞‡∏ö‡∏ö"
            result["violations"].append(f"Prompt-injection attempt: {', '.join(injection_hits)}")
            return result

        
        is_safe, safety_violations = self.check_content_safety(user_input)
        if not is_safe:
            # ‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏Ñ‡∏≥‡∏´‡∏¢‡∏≤‡∏ö‡∏ó‡∏±‡∏ô‡∏ó‡∏µ ‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö PDPA ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            result["should_respond"] = False
            result["response_message"] = "üî¥ [Guardrail] ‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏û‡∏ö‡∏Ñ‡∏≥‡∏´‡∏¢‡∏≤‡∏ö/‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°"
            result["violations"].extend(safety_violations)
            return result

        
        is_pdpa_related, reason_text = self._ai_check_pdpa_related(user_input)
        if not is_pdpa_related:
            result["should_respond"] = False
        
            result["response_message"] = (
                "üî¥ ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö PDPA (‡∏û.‡∏£.‡∏ö.‡∏Ñ‡∏∏‡πâ‡∏°‡∏Ñ‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•)\n"
                f"- {reason_text}\n"
            )
            if reason_text:
                result["reasons"].append(reason_text)
            return result


        return result
    
    def filter_ai_response(self, ai_response: str) -> Dict[str, any]:
        """
        Filter AI-generated responses for safety.
        
        Args:
            ai_response: The AI's response text
            
        Returns:
            Dictionary with filtering results
        """
        result = {
            "is_safe": True,
            "violations": [],
            "filtered_text": ai_response,
            "should_display": True,
            "replacement_message": ""
        }

        ai_response = self.sanitize_pii(ai_response)


        is_safe, safety_violations = self.check_content_safety(ai_response)
        result["is_safe"] = is_safe
        result["violations"].extend(safety_violations)
        
        if not is_safe:
            result["should_display"] = False
            result["replacement_message"] = (
                "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡∏â‡∏±‡∏ô‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡πÑ‡∏î‡πâ "
                "‡πÇ‡∏õ‡∏£‡∏î‡∏•‡∏≠‡∏á‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö PDPA"
            )
        

        injection_hits = self.detect_prompt_injection(ai_response)
        if injection_hits:
            result["violations"].append(
                f"‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô prompt-injection: {', '.join(injection_hits[:3])}"
            )
        return result
    
    def sanitize_text(self, text: str) -> str:
        """
        Sanitize text by removing or replacing inappropriate content.
        """
        if not text:
            return text

        sanitized = self.inappropriate_regex.sub('[REDACTED]', text)
        sanitized = self.sanitize_pii(sanitized)
        return sanitized
