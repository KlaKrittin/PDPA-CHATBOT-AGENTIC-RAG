import argparse
import json
import os
import random
import sys
import re
from typing import Any, Dict, List, Optional
import pandas as pd
from dotenv import load_dotenv
from openai import OpenAI
from qdrant_client import QdrantClient
from tqdm import tqdm
from colorama import Fore, Style, init as colorama_init


import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../")))
from agentic_rag.tools.qdrant_storage import QdrantStorage, MyEmbedder

colorama_init()

DEFAULT_TARGET = 150
DEFAULT_OUTPUT_XLSX = "eval/pdpa_generated.xlsx"
DEFAULT_OUTPUT_JSONL = "eval/pdpa_generated.jsonl"


def _call_llm(prompt: str, temperature: float = 0.3, max_tokens: int = 8192) -> str:
    base_url = (
        os.getenv("LLAMA_CPP_BASE_URL")
        or os.getenv("OPENAI_BASE_URL")
        or "http://localhost:8080/v1"
    )
    model = (
        os.getenv("LLAMA_CPP_MODEL")
        or os.getenv("EVAL_MODEL")
        or "hf.co/scb10x/typhoon2.1-gemma3-4b-gguf:Q4_K_M"
    )
    api_key = os.getenv("OPENAI_API_KEY", "not-needed")

    client = OpenAI(base_url=base_url, api_key=api_key)

    try:
        resp = client.chat.completions.create(
            model=model,
            temperature=temperature,
            max_tokens=max_tokens,
            messages=[
                {
                    "role": "system",
                    "content": (
                        "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô PDPA ‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏£‡πà‡∏á‡∏Ñ‡∏£‡∏±‡∏î‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á "
                        "‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏î‡∏≤ ‡∏´‡πâ‡∏≤‡∏°‡∏™‡∏°‡∏°‡∏ï‡∏¥ ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ "
                        "‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß ‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó ‡πÅ‡∏•‡∏∞‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢ PDPA "
                        "‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏ï‡πà‡∏á‡πÄ‡∏ï‡∏¥‡∏°‡∏ô‡∏≠‡∏Å‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ"
                    ),
                },
                {"role": "user", "content": prompt},
            ],
            timeout=120.0,
        )
        return (resp.choices[0].message.content or "").strip()
    except Exception as e:
        print(Fore.RED + f"‚úò API Error: {e}" + Style.RESET_ALL)
        return ""


def _safe_get(payload: Dict[str, Any], keys: List[str], default: str = "") -> str:
    for k in keys:
        if k in payload and payload[k] is not None:
            return str(payload[k])
    return default



def fetch_contexts(
    client: QdrantClient,
    max_per_collection: int = 0,
    min_text_len: int = 50,
) -> List[Dict[str, Any]]:

    print(Fore.CYAN + "üìÅ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Qdrant Collections (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô Seed)..." + Style.RESET_ALL)
    contexts: List[Dict[str, Any]] = []

    cols_resp = client.get_collections()
    collections = getattr(cols_resp, "collections", []) or []

    print(f"üîç ‡∏û‡∏ö {len(collections)} collections\n")

    for col in collections:
        name = getattr(col, "name", None) or col.get("name")
        if not name:
            continue

        print(Fore.YELLOW + f"‚û° ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô Collection: {name}" + Style.RESET_ALL)

        next_offset = None
        fetched = 0

        while max_per_collection <= 0 or fetched < max_per_collection:
            points, next_offset = client.scroll(
                collection_name=name,
                with_payload=True,
                limit=64,
                offset=next_offset,
            )
            if not points:
                break

            for p in points:
                payload = getattr(p, "payload", None) or p.get("payload")
                if not isinstance(payload, dict):
                    continue

                text_val = payload.get("text")
                if not text_val or len(str(text_val)) < min_text_len:
                    continue

                contexts.append(
                    {
                        "text": str(text_val),
                        "doc_title": _safe_get(
                            payload,
                            ["source_file", "doc_title", "document_title", "file_name", "filename"],
                            "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏ü‡∏•‡πå",
                        ),
                        "page": _safe_get(
                            payload,
                            ["page_number", "page", "page_index", "page_idx"],
                            "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏´‡∏ô‡πâ‡∏≤",
                        ),
                        "collection": name,
                    }
                )

                fetched += 1
                if max_per_collection > 0 and fetched >= max_per_collection:
                    break

            if not next_offset:
                break

        print(f"   ‚úî ‡∏î‡∏∂‡∏á‡πÑ‡∏î‡πâ {fetched} passages\n")

    print(Fore.GREEN + f"üì¶ ‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(contexts)} passages\n" + Style.RESET_ALL)
    return contexts



def generate_question(seed_chunk: Dict[str, Any]) -> str:
    prompt = (
        "‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á '‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°' ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö PDPA 1 ‡∏Ç‡πâ‡∏≠ "
        "‡πÇ‡∏î‡∏¢‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏™‡∏á‡∏™‡∏±‡∏¢ "
        "‡πÉ‡∏´‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Ñ‡∏ô‡∏ñ‡∏≤‡∏°‡∏à‡∏£‡∏¥‡∏á ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏°‡∏≤‡∏Å) "
        "‡πÅ‡∏•‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å "
        "‡∏Ç‡∏≠‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏±‡∏ß‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö\n\n"
        f"‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°:\n{seed_chunk['text']}\n\n"
        "‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° (‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö):"
    )
    question = _call_llm(prompt, temperature=0.7, max_tokens=256)

    return question.strip().strip('"').strip("'")


def retrieve_contexts(storage: QdrantStorage, question: str, top_k: int = 5) -> List[Dict[str, Any]]:

    client = storage.client
    cols_resp = client.get_collections()
    collections = getattr(cols_resp, "collections", []) or []
    
    all_results = []
    query_vector = storage.embedder.encode(question)

    for col in collections:
        name = getattr(col, "name", None) or col.get("name")
        if not name: 
            continue
            
        try:
            results = client.search(
                collection_name=name,
                query_vector=query_vector,
                limit=top_k,
                with_payload=True
            )
            for r in results:
                payload = r.payload or {}
                score = r.score
                all_results.append({
                    "text": payload.get("text", ""),
                    "doc_title": _safe_get(payload, ["source_file", "doc_title", "file_name"], "Unknown"),
                    "page": _safe_get(payload, ["page_number", "page"], "Unknown"),
                    "score": score
                })
        except Exception:
            continue

    all_results.sort(key=lambda x: x["score"], reverse=True)
    return all_results[:top_k]


def generate_answer(question: str, contexts: List[Dict[str, Any]]) -> str:
    context_text = ""
    for idx, ctx in enumerate(contexts, 1):
        context_text += f"[{idx}] ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£: {ctx['doc_title']} | ‡∏´‡∏ô‡πâ‡∏≤: {ctx['page']}\n{ctx['text']}\n\n"

    prompt = (
        f"‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {question}\n\n"
        "‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏°‡∏≤‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ (Retrieved Contexts) "
        "‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô '‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö' ‡∏ó‡∏µ‡πà‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏° ‡πÅ‡∏•‡∏∞‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å PDPA "
        "‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ "
        "**‡∏´‡πâ‡∏≤‡∏°** ‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ '‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤', '‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£', ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏ß‡πà‡∏≤‡∏≠‡πà‡∏≤‡∏ô‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏ö‡∏£‡∏¥‡∏ö‡∏ó ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏•‡∏¢ "
        "**‡∏´‡πâ‡∏≤‡∏°** ‡πÉ‡∏™‡πà‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏•‡∏Ç‡∏´‡∏ô‡πâ‡∏≤‡∏•‡∏á‡πÉ‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö (‡πÄ‡∏ä‡πà‡∏ô ‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ß‡πà‡∏≤ '‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤ 5') "
        "‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏î‡∏≤ ‡∏´‡πâ‡∏≤‡∏°‡∏™‡∏°‡∏°‡∏ï‡∏¥ ‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å "
        "‡∏´‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ï‡∏≠‡∏ö ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÄ‡∏ó‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ\n\n"
        f"‡∏ö‡∏£‡∏¥‡∏ö‡∏ó:\n{context_text}\n\n"
        "‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö (‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏° ‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ ‡πÅ‡∏•‡∏∞**‡πÑ‡∏°‡πà‡∏°‡∏µ**‡∏Ñ‡∏≥‡πÄ‡∏Å‡∏£‡∏¥‡πà‡∏ô‡∏ô‡∏≥‡∏ß‡πà‡∏≤‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•):"
    )
    return _call_llm(prompt, temperature=0.3, max_tokens=2048)



def generate_rag_pairs(
    client: QdrantClient,
    seed_contexts: List[Dict[str, Any]],
    target: int,
    top_k: int
) -> List[Dict[str, str]]:

   
    storage = QdrantStorage(
        type="temp",
        qdrant_location=os.getenv("QDRANT_URL", "http://localhost:6333"),
        qdrant_api_key=os.getenv("QDRANT_API_KEY"),
        embedder=MyEmbedder(os.getenv("RAG_EMBED_MODEL"))
    )

    results: List[Dict[str, str]] = []
    
    print(Fore.CYAN + "üß† ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á Q&A ‡πÅ‡∏ö‡∏ö RAG (Seed -> Gen Q -> Retrieve -> Gen A)...\n" + Style.RESET_ALL)
    pbar = tqdm(total=target, desc="Q&A Generated", colour="green")


    random.shuffle(seed_contexts)
    seed_iter = iter(seed_contexts)

    while len(results) < target:
        try:
            seed = next(seed_iter)
        except StopIteration:
 
            random.shuffle(seed_contexts)
            seed_iter = iter(seed_contexts)
            seed = next(seed_iter)

     
        question = generate_question(seed)
        if not question or len(question) < 10:
            continue

        retrieved = retrieve_contexts(storage, question, top_k=top_k)
        if not retrieved:
            continue

        answer = generate_answer(question, retrieved)
        if not answer or len(answer) < 20:
            continue


        doc_titles = sorted(list(set(r["doc_title"] for r in retrieved)))
        pages = sorted(list(set(r["page"] for r in retrieved)))
        
 
        context_str = "\n\n".join([f"Source: {c['doc_title']} (Page {c['page']})\n{c['text']}" for c in retrieved])

        results.append({
            "question": question,
            "ground_truth": answer,
            "doc_title": ", ".join(doc_titles),
            "page": ", ".join(pages),
            "contexts": context_str
        })
        
        pbar.update(1)

    pbar.close()
    return results


def save_outputs(pairs: List[Dict[str, str]], xlsx_path: str, jsonl_path: Optional[str]):
    print(Fore.CYAN + "üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå..." + Style.RESET_ALL)

    df = pd.DataFrame(pairs, columns=["question", "ground_truth", "doc_title", "page", "contexts"])
    os.makedirs(os.path.dirname(xlsx_path), exist_ok=True)

    df.to_excel(xlsx_path, index=False)
    print(Fore.GREEN + f"‚úî ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô Excel: {xlsx_path}" + Style.RESET_ALL)

    if jsonl_path:
        with open(jsonl_path, "w", encoding="utf-8") as f:
            for row in pairs:
                f.write(json.dumps(row, ensure_ascii=False) + "\n")
        print(Fore.GREEN + f"‚úî ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô JSONL: {jsonl_path}" + Style.RESET_ALL)

    print(Fore.BLUE + "\nüìå ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î!" + Style.RESET_ALL)


def main():
    parser = argparse.ArgumentParser(description="Generate PDPA Q&A using RAG approach.")
    parser.add_argument("--target", type=int, default=DEFAULT_TARGET)
    parser.add_argument("--top_k", type=int, default=5)
    parser.add_argument("--max_per_collection", type=int, default=0)
    parser.add_argument("--output_xlsx", default=DEFAULT_OUTPUT_XLSX)
    parser.add_argument("--output_jsonl", default=DEFAULT_OUTPUT_JSONL)
    args = parser.parse_args()

    load_dotenv()
    client = QdrantClient(
        url=os.getenv("QDRANT_URL", "http://localhost:6333"),
        api_key=os.getenv("QDRANT_API_KEY")
    )


    contexts = fetch_contexts(client, max_per_collection=args.max_per_collection)

    if not contexts:
        print(Fore.RED + "‚úò ERROR: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Qdrant" + Style.RESET_ALL)
        sys.exit(1)

    pairs = generate_rag_pairs(
        client=client,
        seed_contexts=contexts,
        target=args.target,
        top_k=args.top_k
    )

    save_outputs(pairs, args.output_xlsx, args.output_jsonl)


if __name__ == "__main__":
    main()
