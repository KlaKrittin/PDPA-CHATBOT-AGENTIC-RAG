import os
import yaml
from .tools.custom_tool import DocumentSearchTool
from .tools.qdrant_storage import QdrantStorage, MyEmbedder
from langgraph.graph import StateGraph
import logging
from typing import Dict, Any
# Security filter for guardrails
from .tools.security_filter import SecurityFilter
# Import SerperDevTool for web search
try:
    from .tools.serper_tool import SerperDevTool
except ImportError:
    SerperDevTool = None
    logging.warning("SerperDevTool not installed. Please check serper_tool.py if you want web search.")

# Add OpenAI-compatible client (for llama.cpp server)
try:
    from openai import OpenAI
except ImportError:
    OpenAI = None
    logging.warning("OpenAI client not installed. Please install with 'pip install openai'.")

OLLAMA_MODEL = "hf.co/scb10x/typhoon2.1-gemma3-4b-gguf:Q4_K_M"
LLAMA_CPP_BASE_URL = "http://localhost:8080/v1"

AGENTS_YAML = os.path.join(os.path.dirname(__file__), 'config', 'agents.yaml')
TASKS_YAML = os.path.join(os.path.dirname(__file__), 'config', 'tasks.yaml')

# Helper to call llama.cpp (OpenAI-compatible) LLM

def call_llm(prompt, system=None):
    if OpenAI is None:
        raise ImportError("OpenAI client not installed. Run: pip install openai")
    messages = []
    if system:
        messages.append({"role": "system", "content": system})
    messages.append({"role": "user", "content": prompt})
    client = OpenAI(base_url=LLAMA_CPP_BASE_URL, api_key="not-needed")
    response = client.chat.completions.create(
        model=OLLAMA_MODEL,
        messages=messages,
        max_tokens=8192
    )
    return response.choices[0].message.content


def build_langgraph_workflow(pdf_tool=None, use_knowledge_base=True):
    with open(AGENTS_YAML, 'r', encoding='utf-8') as f:
        agents_config = yaml.safe_load(f)
    with open(TASKS_YAML, 'r', encoding='utf-8') as f:
        tasks_config = yaml.safe_load(f)

    # Initialize web search tool if available and API key is set
    web_search_tool = None
    print(f"üîç Checking SerperDevTool availability...")
    print(f"   - SerperDevTool imported: {SerperDevTool is not None}")
    print(f"   - SERPER_API_KEY exists: {os.getenv('SERPER_API_KEY') is not None}")
    
    if SerperDevTool and os.getenv("SERPER_API_KEY"):
        try:
            web_search_tool = SerperDevTool()
            print("‚úÖ SerperDevTool initialized successfully for LangGraph")
            # Debug: ‡∏î‡∏π method ‡∏ó‡∏µ‡πà‡∏°‡∏µ
            print(f"üîç SerperDevTool methods: {[m for m in dir(web_search_tool) if not m.startswith('_')]}")
        except Exception as e:
            print(f"‚ùå Error initializing SerperDevTool: {e}")
            web_search_tool = None
    else:
        if not SerperDevTool:
            print("‚ö†Ô∏è SerperDevTool not available - install serper-dev")
        if not os.getenv("SERPER_API_KEY"):
            print("‚ö†Ô∏è SERPER_API_KEY not set - add to .env file")
        print("‚ö†Ô∏è Web search will be disabled")

    # Initialize security filter (guardrail)
    security_filter = SecurityFilter()

    # --- Node implementations ---
    def append_progress(state, message):
        progress = state.get("progress_log", [])
        return progress + [message]

    def refine_question_node(state):
        query = state.get("query", "")
        progress_log = state.get("progress_log", [])
        # Guardrail: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Å‡πà‡∏≠‡∏ô refine ‡∏´‡∏≤‡∏Å‡∏û‡∏ö‡∏Ñ‡∏≥‡∏´‡∏¢‡∏≤‡∏ö/‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡πÉ‡∏´‡πâ‡∏´‡∏¢‡∏∏‡∏î‡πÅ‡∏•‡∏∞‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô
        try:
            filter_result = security_filter.filter_user_input(query or "")
        except Exception:
            filter_result = {"should_respond": False, "response_message": "‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á"}

        if not filter_result.get("should_respond", True):
            progress_log = append_progress({"progress_log": progress_log}, "üî¥ [Guardrail] ‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏û‡∏ö‡∏Ñ‡∏≥‡∏´‡∏¢‡∏≤‡∏ö/‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°")
            warn_msg = filter_result.get("response_message") or "‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡πÉ‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏û‡∏¥‡∏°‡∏û‡πå‡πÉ‡∏´‡∏°‡πà‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏ñ‡πâ‡∏≠‡∏¢‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏†‡∏≤‡∏û"
            return {**state, "response": warn_msg, "best_answer": "", "blocked": True, "progress_log": progress_log}

        # ‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡πÅ‡∏•‡πâ‡∏ß ‡∏à‡∏∂‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏° refine‡∏´
        progress_log = append_progress({"progress_log": progress_log}, "üü° [LangGraph] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° (Refining question)...")
        system = agents_config['question_refiner_agent']['role'] + "\n" + agents_config['question_refiner_agent']['goal']
        prompt = (
            f"Refine or clarify the following question to make it clear, specific, and actionable.\n"
            f"Question: {query}\n"
            f"‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô"
        )
        refined = call_llm(prompt, system=system)
        progress_log = append_progress({"progress_log": progress_log}, "üü¢ [LangGraph] ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß (Refined question)")
        return {**state, "refined_question": refined, "progress_log": progress_log}

    def planning_node(state):
        progress_log = append_progress(state, "üü° [LangGraph] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô (Planning)...")
        refined = state.get("refined_question", "")
        system = agents_config['planning_agent']['role'] + "\n" + agents_config['planning_agent']['goal']
        prompt = (
            f"Generate a step-by-step plan to answer the following question.\n"
            f"Question: {refined}\n"
            f"‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô"
        )
        plan = call_llm(prompt, system=system)
        progress_log = append_progress({"progress_log": progress_log}, "üü¢ [LangGraph] ‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß (Planning done)")
        return {**state, "plan": plan, "progress_log": progress_log}

    def retrieval_node(state):
        progress_log = append_progress(state, "üü° [LangGraph] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Retrieving from PDF/Knowledge)...")
        query = state.get("query", "")  # ‡πÉ‡∏ä‡πâ query ‡πÄ‡∏î‡∏¥‡∏° ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ refined_question
        tool = pdf_tool if pdf_tool else DocumentSearchTool(file_path=os.path.join(os.path.dirname(__file__), '../../knowledge/pdpa.pdf'))
        retrieved = tool._run(query)
        try:
            print("\n===== DocumentSearchTool Result (truncated) =====")
            if isinstance(retrieved, str):
                preview = retrieved[:2000]
                print(preview)
                if len(retrieved) > len(preview):
                    print(f"... [truncated, total {len(retrieved)} chars]")
            else:
                print(str(retrieved))
            print("===== End DocumentSearchTool Result =====\n")
        except Exception as _:
            pass
        progress_log = append_progress({"progress_log": progress_log}, "üü¢ [LangGraph] ‡∏Ñ‡πâ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß (Retrieval done)")
        return {**state, "retrieved": retrieved, "retrieval_source": "pdf", "progress_log": progress_log}

    def websearch_node(state):
        progress_log = append_progress(state, "üü° [LangGraph] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡πÄ‡∏ß‡πá‡∏ö (Web search fallback)...")
        query = state.get("query", "")  # ‡πÉ‡∏ä‡πâ query ‡πÄ‡∏î‡∏¥‡∏° ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ refined_question
        web_text = ""
        references_text = ""  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô error
        
        # Helper: keep only readable characters and cap length
        import re
        def _clean_text(text: str, max_len: int = 4000) -> str:
            if not isinstance(text, str):
                text = str(text)
            # Remove binary-looking sequences and non-printable chars
            text = re.sub(r"[^\t\n\r\x20-\x7E\u0E00-\u0E7F\u2013\u2014\u2018\u2019\u201C\u201D]", " ", text)
            # Collapse whitespace
            text = re.sub(r"\s+", " ", text).strip()
            if len(text) > max_len:
                return text[:max_len] + " ‚Ä¶(‡∏ï‡∏±‡∏î‡∏ó‡∏≠‡∏ô)"
            return text
        
        if web_search_tool:
            try:
                print(f"üîç Trying to call SerperDevTool with query: '{query}'")
                print(f"üîç Available methods: {[m for m in dir(web_search_tool) if not m.startswith('_')]}")
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö schema ‡∏Ç‡∏≠‡∏á tool
                if hasattr(web_search_tool, 'args_schema'):
                    print(f"üîç Tool args_schema: {web_search_tool.args_schema}")
                    if hasattr(web_search_tool.args_schema, '__annotations__'):
                        print(f"üîç Tool annotations: {web_search_tool.args_schema.__annotations__}")
                if hasattr(web_search_tool, 'schema'):
                    print(f"üîç Tool schema: {web_search_tool.schema}")
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö signature ‡∏Ç‡∏≠‡∏á run method
                import inspect
                if hasattr(web_search_tool, 'run'):
                    try:
                        sig = inspect.signature(web_search_tool.run)
                        print(f"üîç run method signature: {sig}")
                    except Exception as e:
                        print(f"üîç Cannot inspect run method: {e}")
                
                # ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ method ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
                web_result = None
                
                # ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ run method ‡πÅ‡∏ö‡∏ö keyword argument ‡∏Å‡πà‡∏≠‡∏ô
                if hasattr(web_search_tool, 'run'):
                    print("üîç Trying run method with keyword argument")
                    try:
                        web_result = web_search_tool.run(query=query)
                        print("‚úÖ run method with keyword argument succeeded")
                    except Exception as e:
                        print(f"üîç run method with keyword failed: {e}")
                        try:
                            # ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ run method ‡πÅ‡∏ö‡∏ö positional argument
                            web_result = web_search_tool.run(query)
                            print("‚úÖ run method with positional argument succeeded")
                        except Exception as e2:
                            print(f"üîç run method with positional failed: {e2}")
                
                # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ _run method
                if web_result is None and hasattr(web_search_tool, '_run'):
                    print("üîç Trying _run method")
                    try:
                        web_result = web_search_tool._run(query)
                        print("‚úÖ _run method succeeded")
                    except Exception as e:
                        print(f"üîç _run method failed: {e}")
                
                # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡∏•‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
                if web_result is None:
                    print("üîç Trying direct call")
                    try:
                        web_result = web_search_tool.search(query)
                        print("‚úÖ .search method succeeded")
                    except Exception as e:
                        print(f"üîç .search method failed: {e}")
                
                # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢
                if web_result is None:
                    raise Exception("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ SerperDevTool ‡πÑ‡∏î‡πâ")
                
                if isinstance(web_result, dict) and 'organic' in web_result:
                    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á
                    results = web_result['organic']
                    web_text_parts = []
                    references = []
                    web_contents = []
                    combined_chars = 0
                    combined_char_budget = 12000
                    for i, result in enumerate(results):  # ‡∏î‡∏∂‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏∏‡∏Å‡∏•‡∏¥‡∏á‡∏Å‡πå
                        title = result.get('title', '')
                        snippet = result.get('snippet', '')
                        link = result.get('link', '')
                        print(f"üåê [{i+1}] ‡∏≠‡πà‡∏≤‡∏ô‡∏•‡∏¥‡∏á‡∏Å‡πå: {link}")
                        web_text_parts.append(f"{i+1}. {title}\n{_clean_text(snippet, 600)}")
                        references.append(f"[{i+1}] {title}: {link}")
                        # ‡∏î‡∏∂‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö
                        from src.agentic_rag.tools.serper_tool import SerperDevTool
                        content = SerperDevTool.extract_web_content(link, max_chars=200000)
                        cleaned = _clean_text(content, 4000)
                        combined_chars += len(cleaned)
                        print(f"    ‚Ü≥ ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏´‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î: {len(cleaned)} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£")
                        # Append only within budget to avoid overwhelming LLM
                        if combined_chars <= combined_char_budget:
                            web_contents.append(f"---\n{title}\n{link}\n{cleaned}\n")
                        else:
                            web_contents.append(f"---\n{title}\n{link}\n(‡∏ï‡∏±‡∏î‡∏ó‡∏≠‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏ô‡∏≤‡∏î)\n")
                    web_text = '\n\n'.join(web_text_parts) + '\n\n' + '\n'.join(web_contents)
                    references_text = '\n'.join(references)
                    print(f"‚úÖ [LangGraph] Web search successful, found {len(results)} results")
                    print(f"üìö References: {len(references)} sources")
                    # Do not print web_text to avoid huge console noise / binary
                else:
                    web_text = str(web_result)
                    references_text = ""
                    print(f"‚úÖ [LangGraph] Web search successful, raw result")
            except Exception as e:
                print(f"‚ùå [LangGraph] Web search error: {e}")
                web_text = "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡πâ‡∏ô‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏î‡πâ"
        else:
            web_text = "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡πâ‡∏ô‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏î‡πâ (SerperDevTool ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ API Key)"
            print("‚ö†Ô∏è [LangGraph] Web search not available")
        
        # Combine with previous retrieved
        combined = f"[PDF/Knowledge]: {state.get('retrieved', '')}\n[Web]: {web_text}"
        progress_log = append_progress({"progress_log": progress_log}, "üü¢ [LangGraph] ‡∏Ñ‡πâ‡∏ô‡πÄ‡∏ß‡πá‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß (Web search done)")
        return {**state, "retrieved": combined, "retrieval_source": "pdf+web", "web_search_count": state.get("web_search_count", 0) + 1, "web_references": references_text, "progress_log": progress_log}

    def judge_info_node(state):
        progress_log = append_progress(state, "üü° [LangGraph] LLM ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Judging info sufficiency)...")
        refined = state.get("refined_question", "")
        context = state.get("retrieved", "")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏•‡πâ‡∏ß
        web_search_count = state.get("web_search_count", 0)
        if web_search_count >= 3:
            print("üü° [LangGraph] ‡πÄ‡∏Å‡∏¥‡∏ô‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏•‡πâ‡∏ß - ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ")
            return {**state, "info_sufficient": True, "judge_reason": "‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏•‡πâ‡∏ß", "progress_log": progress_log}
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if not context or context.strip() in ["‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á", "‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö PDPA ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô", "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡πâ‡∏ô‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏î‡πâ"]:
            print("üü° [LangGraph] ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠ - ‡∏à‡∏∞‡πÉ‡∏ä‡πâ web search")
            return {**state, "info_sufficient": False, "judge_reason": "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠", "web_search_count": web_search_count + 1, "progress_log": progress_log}
        
        system = "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°"
        prompt = (
            f"‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {refined}\n"
            f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Ñ‡πâ‡∏ô‡∏û‡∏ö: {context}\n"
            f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà?\n"
            f"‡∏ñ‡πâ‡∏≤‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠ ‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ '‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠'\n‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠ ‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ '‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠' ‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≤‡∏î‡∏≠‡∏∞‡πÑ‡∏£\n‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô"
        )
        judge = call_llm(prompt, system=system)
        progress_log = append_progress({"progress_log": progress_log}, f"üü¢ [LangGraph] LLM ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÅ‡∏•‡πâ‡∏ß: {judge.strip()}")
        # Simple logic: if '‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠' in answer and not '‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠' => sufficient
        is_sufficient = ('‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠' in judge and '‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠' not in judge)
        return {**state, "info_sufficient": is_sufficient, "judge_reason": judge.strip(), "progress_log": progress_log}

    def generate_answers_node(state):
        progress_log = append_progress(state, "üü° [LangGraph] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏ö‡∏ö (Generating multiple answers)...")
        refined = state.get("refined_question", "")
        context = state.get("retrieved", "")
        system = agents_config['answer_candidate_agent']['role'] + "\n" + agents_config['answer_candidate_agent']['goal']

        num_candidates = 3
        candidates = []
        for i in range(num_candidates):
            prompt = (
                f"Using the following context, write ONE comprehensive, structured answer to the question.\n"
                f"Context: {context}\n"
                f"Question: {refined}\n"
                f"\n‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î:\n"
                f"- ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏ä‡∏¥‡∏á‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‡∏†‡∏≤‡∏¢‡πÉ‡∏ï‡πâ PDPA ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ó‡∏¢‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n"
                f"- ‡∏´‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠ ‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤ '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠' ‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏≤‡∏á‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥\n"
                f"- ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏£‡∏ö‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏°‡∏≤‡∏ï‡∏£‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô\n"
                f"- ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢ ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢ (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢)\n"
                f"- ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ô‡∏µ‡πâ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏≠‡∏∑‡πà‡∏ô ‡πÜ (‡∏´‡∏≤‡∏Å‡∏°‡∏µ)\n"
                f"\n‡∏≠‡∏¢‡πà‡∏≤‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏≠‡∏∑‡πà‡∏ô ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÄ‡∏û‡∏µ‡∏¢‡∏á 1 ‡∏ä‡∏∏‡∏î‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n"
            )
            try:
                answer = call_llm(prompt, system=system).strip()
            except Exception as e:
                answer = f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ó‡∏µ‡πà {i+1} ‡πÑ‡∏î‡πâ: {e}"
            candidates.append(answer)

        progress_log = append_progress({"progress_log": progress_log}, f"üü¢ [LangGraph] ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß {len(candidates)} ‡πÅ‡∏ö‡∏ö (Candidates ready)")
        return {**state, "candidates": candidates, "progress_log": progress_log}

    def decision_ranking_node(state):
        progress_log = append_progress(state, "üü° [LangGraph] ‡∏à‡∏±‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö (Ranking candidates)...")
        candidates = state.get("candidates", [])
        refined = state.get("refined_question", "")
        if not candidates:
            progress_log = append_progress({"progress_log": progress_log}, "üü° [LangGraph] ‡πÑ‡∏°‡πà‡∏°‡∏µ candidates ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö")
            return {**state, "ranked": [], "best_answer": state.get("best_answer", ""), "progress_log": progress_log}

        system = agents_config['decision_ranking_agent']['role'] + "\n" + agents_config['decision_ranking_agent']['goal']
        indexed = "\n".join([f"[{i+1}]\n{c}" for i, c in enumerate(candidates)])
        prompt = (
            f"Evaluate the following candidate answers for the question and return ONLY a comma-separated list of indices from best to worst (e.g., 2,1,3).\n"
            f"Question: {refined}\n"
            f"Candidates:\n{indexed}\n"
            f"\n‡∏ï‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏î‡∏±‡∏ä‡∏ô‡∏µ‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏à‡∏∏‡∏•‡∏†‡∏≤‡∏Ñ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô (‡πÄ‡∏ä‡πà‡∏ô 2,1,3) ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏Å‡πá‡πÑ‡∏î‡πâ ‡πÅ‡∏ï‡πà‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏∑‡πà‡∏ô"
        )
        order_text = call_llm(prompt, system=system)
        import re
        nums = re.findall(r"\d+", order_text)
        order = [int(n)-1 for n in nums if 1 <= int(n) <= len(candidates)]
        # Ensure we have a full permutation; append any missing indices in original order
        missing = [i for i in range(len(candidates)) if i not in order]
        order.extend(missing)

        ranked = [candidates[i] for i in order]
        best_answer = ranked[0] if ranked else ""
        progress_log = append_progress({"progress_log": progress_log}, "üü¢ [LangGraph] ‡∏à‡∏±‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß (Ranking done)")
        return {**state, "ranked": ranked, "candidates": ranked, "best_answer": best_answer, "progress_log": progress_log}

    def response_node(state):
        progress_log = append_progress(state, "üü° [LangGraph] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö (Synthesizing response)...")
        ranked = state.get("ranked", [])
        best_answer = state.get("best_answer", "")
        web_references = state.get("web_references", "")
        
        if best_answer:
            # ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢ ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏£‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô
            system = agents_config['response_synthesizer_agent']['role'] + "\n" + agents_config['response_synthesizer_agent']['goal']
            prompt = (
                f"‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢ ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏¢‡πà‡∏≠‡∏¢ ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÉ‡∏´‡∏°‡πà:\n"
                f"‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÄ‡∏î‡∏¥‡∏°: {best_answer}\n"
                f"\n‚ö†Ô∏è ‡∏Å‡∏é‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:\n"
                f"- ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≤‡∏° ‡∏û.‡∏£.‡∏ö. ‡∏Ñ‡∏∏‡πâ‡∏°‡∏Ñ‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏• ‡∏û.‡∏®. 2562 ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n"
                f"- ‡∏´‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠ ‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤ '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠' ‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç\n"
                f"- ‡πÉ‡∏ä‡πâ bullet points (‚Ä¢) ‡πÅ‡∏•‡∏∞‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô\n"
                f"- ‡πÄ‡∏ô‡πâ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢ ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏£‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô\n"
                f"- ‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÄ‡∏î‡∏¥‡∏°\n"
                f"\n‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô"
            )
            response = call_llm(prompt, system=system)
        else:
            # Fallback to synthesizing from ranked answers
            system = agents_config['response_synthesizer_agent']['role'] + "\n" + agents_config['response_synthesizer_agent']['goal']
            prompt = (
                f"Select the top-ranked answer and format it as the final response.\n"
                f"Answers: {ranked}\n"
                f"\n‚ö†Ô∏è ‡∏Å‡∏é‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≤‡∏° ‡∏û.‡∏£.‡∏ö. ‡∏Ñ‡∏∏‡πâ‡∏°‡∏Ñ‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏• ‡∏û.‡∏®. 2562 ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n"
                f"‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô"
            )
            response = call_llm(prompt, system=system)
        
        progress_log = append_progress({"progress_log": progress_log}, "üü¢ [LangGraph] ‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß (Response ready)")
        return {**state, "response": response, "best_answer": best_answer, "web_references": web_references, "progress_log": progress_log}

    # --- Build the graph ---
    graph = StateGraph(Dict[str, Any])
    graph.add_node("refine_question", refine_question_node)
    graph.add_node("planning", planning_node)
    graph.add_node("retrieval", retrieval_node)
    graph.add_node("websearch", websearch_node)
    graph.add_node("judge_info", judge_info_node)
    graph.add_node("generate_answers", generate_answers_node)
    graph.add_node("decision_ranking", decision_ranking_node)
    graph.add_node("response", response_node)

    # Wiring: retrieval -> judge_info
    graph.set_entry_point("refine_question")
    graph.add_conditional_edges(
        "refine_question",
        lambda state: "response" if state.get("blocked") else "planning"
    )
    graph.add_edge("planning", "retrieval")
    graph.add_edge("retrieval", "judge_info")
    # If info sufficient, go to generate_answers; else, go to websearch
    graph.add_conditional_edges(
        "judge_info",
        lambda state: "generate_answers" if state.get("info_sufficient") else "websearch"
    )
    # After websearch, judge again
    graph.add_edge("websearch", "judge_info")
    # After info is sufficient, continue with ranking then response
    graph.add_edge("generate_answers", "decision_ranking")
    graph.add_edge("decision_ranking", "response")
    graph.set_finish_point("response")

    return graph.compile()
